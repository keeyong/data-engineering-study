{"paragraphs":[{"text":"%spark.pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row","user":"anonymous","dateUpdated":"2018-07-10T04:26:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1531196592096_678167119","id":"20180710-042312_1645131863","dateCreated":"2018-07-10T04:23:12+0000","dateStarted":"2018-07-10T04:26:58+0000","dateFinished":"2018-07-10T04:26:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1345"},{"text":"%spark.pyspark\nfrom os.path import expanduser, join, abspath\nwarehouse_location = abspath('spark-warehouse')\n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark SQL Hive integration example\") \\\n    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n    .enableHiveSupport() \\\n    .getOrCreate()","user":"anonymous","dateUpdated":"2018-07-10T04:26:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1531196643394_-130697663","id":"20180710-042403_1789983812","dateCreated":"2018-07-10T04:24:03+0000","dateStarted":"2018-07-10T04:26:58+0000","dateFinished":"2018-07-10T04:26:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1346"},{"text":"%spark.pyspark\nspark.sql(\"show databases\").show()","user":"anonymous","dateUpdated":"2018-07-10T04:26:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+\n|databaseName|\n+------------+\n|     default|\n+------------+\n\n"}]},"apps":[],"jobName":"paragraph_1531196694516_871465953","id":"20180710-042454_954447530","dateCreated":"2018-07-10T04:24:54+0000","dateStarted":"2018-07-10T04:26:59+0000","dateFinished":"2018-07-10T04:26:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1347"},{"text":"%spark.pyspark\nspark.sql(\"show tables\").show()","user":"anonymous","dateUpdated":"2018-07-10T21:54:09+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+---------+-----------+\n|database|tableName|isTemporary|\n+--------+---------+-----------+\n| default|    test1|      false|\n| default|    test2|      false|\n+--------+---------+-----------+\n\n"}]},"apps":[],"jobName":"paragraph_1531196776053_2021951652","id":"20180710-042616_1222398287","dateCreated":"2018-07-10T04:26:16+0000","dateStarted":"2018-07-10T21:54:09+0000","dateFinished":"2018-07-10T21:54:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1348"},{"text":"%spark.pyspark\nspark.sql(\"desc test1\").show()","user":"anonymous","dateUpdated":"2018-07-10T04:26:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+---------+-------+\n|col_name|data_type|comment|\n+--------+---------+-------+\n|     _c0|      int|   null|\n|     _c1|      int|   null|\n|     _c2|      int|   null|\n+--------+---------+-------+\n\n"}]},"apps":[],"jobName":"paragraph_1531196803486_387400407","id":"20180710-042643_1573856002","dateCreated":"2018-07-10T04:26:43+0000","dateStarted":"2018-07-10T04:26:59+0000","dateFinished":"2018-07-10T04:26:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1349"},{"text":"%spark.pyspark\nspark.sql(\"select count(1) from test1\").show()","user":"anonymous","dateUpdated":"2018-07-10T21:53:16+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+\n|count(1)|\n+--------+\n|       1|\n+--------+\n\n"}]},"apps":[],"jobName":"paragraph_1531196818964_1149233878","id":"20180710-042658_965766843","dateCreated":"2018-07-10T04:26:58+0000","dateStarted":"2018-07-10T21:53:16+0000","dateFinished":"2018-07-10T21:53:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1350"},{"text":"%spark.pyspark\nsqlContext.sql(\"select * from test1 CROSS JOIN test1\").show()","user":"anonymous","dateUpdated":"2018-07-10T04:31:33+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+---+---+---+---+---+\n|_c0|_c1|_c2|_c0|_c1|_c2|\n+---+---+---+---+---+---+\n|  1|  2|  3|  1|  2|  3|\n+---+---+---+---+---+---+\n\n"}]},"apps":[],"jobName":"paragraph_1531197035084_-443936341","id":"20180710-043035_777563929","dateCreated":"2018-07-10T04:30:35+0000","dateStarted":"2018-07-10T04:31:33+0000","dateFinished":"2018-07-10T04:31:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1351"},{"text":"%spark.pyspark\n# https://stackoverflow.com/questions/47605552/passing-spark-dataframe-columns-to-geohash-function-pyspark-cannot-convert-co\nspark.sql(\"create table test2 (id int, message string)\")","user":"anonymous","dateUpdated":"2018-07-10T21:53:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1531197084076_1366969462","id":"20180710-043124_918401831","dateCreated":"2018-07-10T04:31:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1352","dateFinished":"2018-07-10T21:53:54+0000","dateStarted":"2018-07-10T21:53:53+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[]\n"}]}},{"text":"%spark.pyspark\n","user":"anonymous","dateUpdated":"2018-07-11T00:27:48+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1531268868251_-1524965398","id":"20180711-002748_1377120913","dateCreated":"2018-07-11T00:27:48+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1900","errorMessage":""}],"name":"PySpark SparkSQL","id":"2DKFQ3B9S","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}